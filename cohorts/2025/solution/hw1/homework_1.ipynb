{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a180c0cc-5210-45ac-89b6-f4474fedd418",
   "metadata": {},
   "source": [
    "## Module 1 Homework (2025 cohort)\n",
    "\n",
    "In this homework, we’re going to download finance data from various\n",
    "sources and make simple calculations or analysis.\n",
    "\n",
    "### Question 1: \\[Index\\] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia’s [S&P 500 companies\n",
    "page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies),\n",
    "download the data including the year each company was added to the\n",
    "index.\n",
    "\n",
    "Hint: you can use\n",
    "[pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html)\n",
    "to scrape the data into a DataFrame.\n",
    "\n",
    "Steps: \n",
    "1. Create a DataFrame with company tickers, names, and the year\n",
    "they were added. \n",
    "2. Extract the year from the addition date and\n",
    "calculate the number of stocks added each year.\n",
    "3. Which year had the\n",
    "highest number of additions (1957 doesn’t count, as it was the year when\n",
    "the S&P 500 index was founded)?\n",
    "**Write down this year as your answer (the\n",
    "most recent one, if you have several records)**.\n",
    "\n",
    "*Context*: \\> “Following the announcement, all four new entrants saw\n",
    "their stock prices rise in extended trading on Friday” - recent examples\n",
    "of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq\n",
    "article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for\n",
    "more than 20 years? \n",
    "\n",
    "When stocks are added to the S&P 500, they usually\n",
    "experience a price bump as investors and index funds buy shares\n",
    "following the announcement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7b59cf-9a75-445b-91a6-b30e0bae635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b4145e-bb37-4abd-aed3-08e0b54ec415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>year_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery &amp; Supplies &amp; Components</td>\n",
       "      <td>White Plains, New York</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>1524472</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td>1927</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td>1952</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol             Security             GICS Sector  \\\n",
       "0      MMM                   3M             Industrials   \n",
       "1      AOS          A. O. Smith             Industrials   \n",
       "2      ABT  Abbott Laboratories             Health Care   \n",
       "3     ABBV               AbbVie             Health Care   \n",
       "4      ACN            Accenture  Information Technology   \n",
       "..     ...                  ...                     ...   \n",
       "498    XYL           Xylem Inc.             Industrials   \n",
       "499    YUM          Yum! Brands  Consumer Discretionary   \n",
       "500   ZBRA   Zebra Technologies  Information Technology   \n",
       "501    ZBH        Zimmer Biomet             Health Care   \n",
       "502    ZTS               Zoetis             Health Care   \n",
       "\n",
       "                                GICS Sub-Industry    Headquarters Location  \\\n",
       "0                        Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "1                               Building Products     Milwaukee, Wisconsin   \n",
       "2                           Health Care Equipment  North Chicago, Illinois   \n",
       "3                                   Biotechnology  North Chicago, Illinois   \n",
       "4                  IT Consulting & Other Services          Dublin, Ireland   \n",
       "..                                            ...                      ...   \n",
       "498  Industrial Machinery & Supplies & Components   White Plains, New York   \n",
       "499                                   Restaurants     Louisville, Kentucky   \n",
       "500            Electronic Equipment & Instruments   Lincolnshire, Illinois   \n",
       "501                         Health Care Equipment          Warsaw, Indiana   \n",
       "502                               Pharmaceuticals   Parsippany, New Jersey   \n",
       "\n",
       "    Date added      CIK      Founded  year_added  \n",
       "0   1957-03-04    66740         1902        1957  \n",
       "1   2017-07-26    91142         1916        2017  \n",
       "2   1957-03-04     1800         1888        1957  \n",
       "3   2012-12-31  1551152  2013 (1888)        2012  \n",
       "4   2011-07-06  1467373         1989        2011  \n",
       "..         ...      ...          ...         ...  \n",
       "498 2011-11-01  1524472         2011        2011  \n",
       "499 1997-10-06  1041061         1997        1997  \n",
       "500 2019-12-23   877212         1969        2019  \n",
       "501 2001-08-07  1136869         1927        2001  \n",
       "502 2013-06-21  1555280         1952        2013  \n",
       "\n",
       "[503 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0]\n",
    "comp_df['Date added']= pd.to_datetime(comp_df['Date added'])\n",
    "comp_df['year_added'] = comp_df['Date added'].dt.year\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff79df5-f083-424b-b0d6-186fe574ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   Symbol                 503 non-null    object        \n",
      " 1   Security               503 non-null    object        \n",
      " 2   GICS Sector            503 non-null    object        \n",
      " 3   GICS Sub-Industry      503 non-null    object        \n",
      " 4   Headquarters Location  503 non-null    object        \n",
      " 5   Date added             503 non-null    datetime64[ns]\n",
      " 6   CIK                    503 non-null    int64         \n",
      " 7   Founded                503 non-null    object        \n",
      " 8   year_added             503 non-null    int32         \n",
      "dtypes: datetime64[ns](1), int32(1), int64(1), object(6)\n",
      "memory usage: 33.5+ KB\n"
     ]
    }
   ],
   "source": [
    "comp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80f1c00-1c20-4740-a4d8-452db324be2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year_added\n",
       "2016    23\n",
       "2017    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_additions = comp_df[comp_df['year_added'] != 1957].groupby('year_added').size()\n",
    "max_additions_count = yearly_additions.max()\n",
    "max_additions_year = yearly_additions[yearly_additions == max_additions_count]\n",
    "max_additions_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9a7e6-e82b-478d-993f-6ee7d5d3fff0",
   "metadata": {},
   "source": [
    "### Question 2. \\[Macro\\] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the\n",
    "US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD)\n",
    "performance (1 January-1 May 2025) of major stock market indexes for the\n",
    "following countries: \n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China -Shanghai Composite (000001.SS) \n",
    "* Hong Kong - HANG SENG INDEX (^HSI)  \n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date=‘2025-01-01’ and end_date=‘2025-05-01’ when\n",
    "downloading daily data in yfinance\n",
    "\n",
    "Context: \\> [Global Valuations: Who’s Cheap, Who’s\n",
    "Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update)\n",
    "article suggests “Other regions may be growing faster than the US and\n",
    "you need to diversify.”\n",
    "\n",
    "Reference: Yahoo Finance World Indices -\n",
    "https://finance.yahoo.com/world-indices/\n",
    "\n",
    "*Additional*: How many of these indexes have better returns than the S&P\n",
    "500 over 3, 5, and 10 year periods? Do you see the same trend? Note: For\n",
    "simplicity, ignore currency conversion effects.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815c73e8-7232-4c8a-9b4a-6b4df453b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a8c15-5559-41f9-b054-4dcf979ee0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YTD Returns (1 Jan 2025 - 1 May 2025):\n",
      "                          Index  YTD Return\n",
      "9           Mexico - IPC Mexico   13.049444\n",
      "2   Hong Kong - HANG SENG INDEX   12.720018\n",
      "10            Brazil - Ibovespa   12.438710\n",
      "6                 Germany - DAX   12.346378\n",
      "7     United Kingdom - FTSE 100    2.842590\n",
      "4              India - Nifty 50    2.490424\n",
      "1    China - Shanghai Composite    0.504817\n",
      "5    Canada - S&P/TSX Composite   -0.226126\n",
      "3       Australia - S&P/ASX 200   -0.914500\n",
      "0       United States - S&P 500   -5.103301\n",
      "8            Japan - Nikkei 225   -8.297931\n",
      "\n",
      "Number of indices with better YTD returns than the S&P 500: 9\n",
      "\n",
      "Indices with better YTD returns than the S&P 500:\n",
      "                          Index  YTD Return\n",
      "9           Mexico - IPC Mexico   13.049444\n",
      "2   Hong Kong - HANG SENG INDEX   12.720018\n",
      "10            Brazil - Ibovespa   12.438710\n",
      "6                 Germany - DAX   12.346378\n",
      "7     United Kingdom - FTSE 100    2.842590\n",
      "4              India - Nifty 50    2.490424\n",
      "1    China - Shanghai Composite    0.504817\n",
      "5    Canada - S&P/TSX Composite   -0.226126\n",
      "3       Australia - S&P/ASX 200   -0.914500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the indices and their tickers\n",
    "indices = {\n",
    "    \"United States - S&P 500\": \"^GSPC\",\n",
    "    \"China - Shanghai Composite\": \"000001.SS\",\n",
    "    \"Hong Kong - HANG SENG INDEX\": \"^HSI\",\n",
    "    \"Australia - S&P/ASX 200\": \"^AXJO\",\n",
    "    \"India - Nifty 50\": \"^NSEI\",\n",
    "    \"Canada - S&P/TSX Composite\": \"^GSPTSE\",\n",
    "    \"Germany - DAX\": \"^GDAXI\",\n",
    "    \"United Kingdom - FTSE 100\": \"^FTSE\",\n",
    "    \"Japan - Nikkei 225\": \"^N225\",\n",
    "    \"Mexico - IPC Mexico\": \"^MXX\",\n",
    "    \"Brazil - Ibovespa\": \"^BVSP\",\n",
    "}\n",
    "\n",
    "# Define the date range\n",
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-05-01\"\n",
    "\n",
    "# Download data for all indices\n",
    "data = {name: yf.download(ticker, start=start_date, end=end_date) for name, ticker in indices.items()}\n",
    "\n",
    "# Calculate YTD returns\n",
    "returns = {}\n",
    "for name, df in data.items():\n",
    "    if not df.empty:\n",
    "        start_price = df['Close'].iloc[0]\n",
    "        end_price = df['Close'].iloc[-1]\n",
    "        ytd_return = ((end_price - start_price) / start_price) * 100\n",
    "        returns[name] = ytd_return.values[0]\n",
    "\n",
    "# Convert returns to a DataFrame\n",
    "returns_df = pd.DataFrame(list(returns.items()), columns=[\"Index\", \"YTD Return\"])\n",
    "returns_df.sort_values(by=\"YTD Return\", ascending=False, inplace=True)\n",
    "\n",
    "# Find how many indices have better returns than the S&P 500\n",
    "sp500_return = returns[\"United States - S&P 500\"]\n",
    "better_than_sp500 = returns_df[returns_df[\"YTD Return\"] > sp500_return]\n",
    "\n",
    "# Output results\n",
    "print(\"YTD Returns (1 Jan 2025 - 1 May 2025):\")\n",
    "print(returns_df)\n",
    "print(f\"Number of indices with better YTD returns than the S&P 500: {len(better_than_sp500)}\")\n",
    "print(\"Indices with better YTD returns than the S&P 500:\")\n",
    "print(better_than_sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6514ef-667f-4662-8f1c-a87cda1029c7",
   "metadata": {},
   "source": [
    "### Question 3. \\[Index\\] S&P 500 Market Corrections Analysis\n",
    "\n",
    "**Calculate the median duration (in days) of significant market\n",
    "corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes\n",
    "down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps: \n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous\n",
    "prices) \n",
    "3. For each pair of consecutive all-time highs, find the minimum\n",
    "price in between \n",
    "4. Calculate drawdown percentages: (high - low) / high\n",
    "× 100 \n",
    "5. Filter for corrections with at least 5% drawdown \n",
    "6. Calculate the duration in days for each correction period \n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \\> \\* Investors often wonder about the typical length of\n",
    "market corrections when deciding “when to buy the dip” ([Reddit\n",
    "discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> -   [A Wealth of Common Sense - How Often Should You Expect a Stock\n",
    ">     Market\n",
    ">     Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of\n",
    "top 10 largest corrections by drawdown: \n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days \n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days \n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days \n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days \n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days \n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days \n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days \n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7e00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gspc_df = yf.download(\"^GSPC\", start=\"1950-01-01\", auto_adjust=True)[\"Close\"]\n",
    "gspc_df.columns = ['Close']\n",
    "\n",
    "gspc_df['AllTimeHigh'] = gspc_df['Close'].cummax()\n",
    "all_time_highs = gspc_df[gspc_df['Close'] == gspc_df['AllTimeHigh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a411b7-1798-4f49-a23c-064aabc856fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = []\n",
    "all_time_highs_list = all_time_highs.index.to_list()\n",
    "\n",
    "for i in range(len(all_time_highs_list) - 1):\n",
    "    start_date = all_time_highs_list[i]\n",
    "    end_date = all_time_highs_list[i + 1]\n",
    "    \n",
    "    segment = gspc_df.loc[start_date:end_date]\n",
    "    if segment.empty:\n",
    "        continue\n",
    "    min_date= segment['Close'].idxmin()\n",
    "    min_price = segment.loc[min_date]['Close']\n",
    "    \n",
    "    peak_price = gspc_df.loc[start_date]['Close']\n",
    "    drawdown_pct = ((peak_price - min_price) / peak_price) * 100\n",
    "    \n",
    "    if drawdown_pct > 5:\n",
    "        duration = (min_date - start_date).days\n",
    "        corrections.append({\n",
    "            'Start': start_date,\n",
    "            'Trough': min_date,\n",
    "            'End': end_date,\n",
    "            'Peak Price': peak_price,\n",
    "            'Trough Price': min_price,\n",
    "            'Drawdown (%)': drawdown_pct,\n",
    "            'Duration (days)': duration\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f490c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction Duration Percentiles (in days):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25    21.5\n",
       "0.50    39.0\n",
       "0.75    89.0\n",
       "Name: Duration (days), dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_df = pd.DataFrame(corrections)\n",
    "percentiles = corrections_df['Duration (days)'].quantile([0.25, 0.5, 0.75])\n",
    "median_duration = percentiles[0.5]\n",
    "\n",
    "print(\"Correction Duration Percentiles (in days):\")\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95afee-0ceb-4d85-958c-a13cc01c2d03",
   "metadata": {},
   "source": [
    "### Question 4. \\[Stocks\\] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following\n",
    "positive earnings surprises days.**\n",
    "\n",
    "Steps: \n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv))\n",
    "containing earnings dates, EPS estimates, and actual EPS. Make sure you\n",
    "are using the correct delimiter to read the data, such as in this\n",
    "command `python pandas.read_csv(\"ha1_Amazon.csv\", delimiter=';')` \n",
    "2. Download complete historical price data using yfinance \n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the *return*as Close_Day3 / Close_Day1 - 1.(Assume Day 2 may correspond to the earnings announcement.) \n",
    "4. Identify positive earnings surprises (where “actual EPS \\> estimated EPS” OR “Surprise (%)\\>0”) \n",
    "5. Calculate 2-day percentage changes following positive earnings surprises. \n",
    "Show your answer in % (closest number to the 2nd digit): *return* \\* 100.0 6.\n",
    "\n",
    "(Optional) Compare the median 2-day percentage change for positive\n",
    "surprises vs. all historical dates. Do you see the difference?\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst\n",
    "expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar -\n",
    "https://finance.yahoo.com/calendar/earnings?symbol=AMZN\n",
    "\n",
    "*Additional*: Is there a correlation between the magnitude of the\n",
    "earnings surprise and the stock price reaction? Does the market react\n",
    "differently to earnings surprises during bull vs. bear markets?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e00b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95203895-589e-45c3-8be1-2799013c2144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company</th>\n",
       "      <th>Earnings Date</th>\n",
       "      <th>EPS Estimate</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>Surprise (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>2026-04-29</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>???.36</td>\n",
       "      <td>???.59</td>\n",
       "      <td>+16.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol           Company Earnings Date EPS Estimate Reported EPS  \\\n",
       "0   AMZN    Amazon.com Inc    2026-04-29            -            -   \n",
       "1   AMZN    Amazon.com Inc    2026-02-04            -            -   \n",
       "2   AMZN    Amazon.com Inc    2025-10-29            -            -   \n",
       "3   AMZN    Amazon.com Inc    2025-07-30            -            -   \n",
       "4   AMZN  Amazon.com, Inc.    2025-05-01       ???.36       ???.59   \n",
       "\n",
       "  Surprise (%)  \n",
       "0            -  \n",
       "1            -  \n",
       "2            -  \n",
       "3            -  \n",
       "4       +16.74  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load earnings data\n",
    "amazon_earnings_df = pd.read_csv(\"../../ha1_Amazon.csv\", sep=';')\n",
    "\n",
    "# Preprocess: Clean and convert earnings date\n",
    "def parse_date(d):\n",
    "    try:\n",
    "        return pd.to_datetime(d.split(\" at\")[0])\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "amazon_earnings_df[\"Earnings Date\"] = amazon_earnings_df[\"Earnings Date\"].apply(parse_date)\n",
    "amazon_earnings_df = amazon_earnings_df.dropna(subset=[\"Earnings Date\"])\n",
    "amazon_earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf17a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert “Surprise (%)” strings (“-”, “+16.74”, etc.) to float, with “-” → NaN\n",
    "def parse_surprise(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        if val == \"-\" or val == \"\":\n",
    "            return np.nan\n",
    "        # Remove leading “+” if present, strip the “%” if present\n",
    "        val = val.lstrip(\"+\").rstrip(\"%\").replace(\",\", \".\")\n",
    "        try:\n",
    "            return float(val)\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# Clean EPS Estimate and Reported EPS columns\n",
    "def parse_eps(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        val = val.replace(\"???\", \"0\")\n",
    "        try:\n",
    "            return float(val)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "    \n",
    "amazon_earnings_df[\"Surprise (%)\"] = amazon_earnings_df[\"Surprise (%)\"].apply(parse_surprise)\n",
    "amazon_earnings_df[\"EPS Estimate\"] = amazon_earnings_df[\"EPS Estimate\"].apply(parse_eps)\n",
    "amazon_earnings_df[\"Reported EPS\"] = amazon_earnings_df[\"Reported EPS\"].apply(parse_eps)\n",
    "\n",
    "positive_anonce_df = amazon_earnings_df[amazon_earnings_df[\"Surprise (%)\"] > 0].copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ee1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df = yf.download(\"AMZN\", start=\"2005-01-01\", progress=False)[[\"Close\"]]\n",
    "amazon_df = amazon_df.rename_axis(\"Date\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "728be5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median 2-day % change on ALL trading dates: 0.1806%\n",
      "Median 2-day % change AFTER positive earnings surprises: -1.9855%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compute 2-day percent changes for every trading date:\n",
    "# Return = (Close on Day 3) / (Close on Day 1) – 1\n",
    "amazon_df[\"Day1_Close\"] = amazon_df[\"Close\"]\n",
    "amazon_df[\"Day3_Close\"] = amazon_df[\"Close\"].shift(-2)\n",
    "amazon_df[\"2d_pct_change\"] = (amazon_df[\"Day3_Close\"] / amazon_df[\"Day1_Close\"]) - 1\n",
    "\n",
    "def find_next_trading_day(target_date, trading_series):\n",
    "    future = trading_series[trading_series >= target_date]\n",
    "    return future.min() if not future.empty else None\n",
    "\n",
    "price_dates = amazon_df[\"Date\"]\n",
    "positive_changes = []\n",
    "\n",
    "for _, row in positive_anonce_df.iterrows():\n",
    "    earnings_date = row[\"Earnings Date\"]\n",
    "    day2 = find_next_trading_day(earnings_date, price_dates)\n",
    "    if day2 is not None:\n",
    "        idx = amazon_df.index[amazon_df[\"Date\"] == day2]\n",
    "        if len(idx) and idx[0] < len(amazon_df) - 2:  # ensure a 2-day window exists\n",
    "            positive_changes.append(amazon_df.loc[idx[0], \"2d_pct_change\"])\n",
    "\n",
    "historical_median = amazon_df[\"2d_pct_change\"].median()\n",
    "positive_median = np.nanmedian(positive_changes)\n",
    "\n",
    "print(f\"Median 2-day % change on ALL trading dates: {historical_median:.4%}\")\n",
    "print(f\"Median 2-day % change AFTER positive earnings surprises: {positive_median:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43760836-ec2f-4a3f-b23f-9d9622df6c86",
   "metadata": {},
   "source": [
    "### Question 5. \\[Exploratory, optional\\] Brainstorm potential idea for your capstone project\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Describe the capstone project you would like to pursue, considering your\n",
    "aspirations, ML model predictions, and prior knowledge. Even if you are\n",
    "unsure at this stage, try to generate an idea you would like to\n",
    "explore-such as a specific asset class, country, industry vertical, or\n",
    "investment strategy. Be as specific as possible.\n",
    "\n",
    "*Example: I want to build a short-term prediction model for the\n",
    "US/India/Brazil stock markets, focusing on the largest stocks over a\n",
    "30-day investment horizon. I plan to use RSI and MACD technical\n",
    "indicators and news coverage data to generate predictions.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2069f6-76eb-4b3e-997f-c1e5a8ec9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea11732-7a3e-4804-9ee0-0b41d2c7c96e",
   "metadata": {},
   "source": [
    "### Question 6. \\[Exploratory, optional\\] Investigate new metrics\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Using the data sources we have covered (or any others you find\n",
    "relevant), download and explore a few additional metrics or time series\n",
    "that could be valuable for your project. Briefly explain why you think\n",
    "each metric is useful. This does not need to be a comprehensive\n",
    "list-focus on demonstrating your ability to generate data requests based\n",
    "on your project description, identify and locate the necessary data, and\n",
    "explain how you would retrieve it using Python.\n",
    "\n",
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting:\n",
    "https://courses.datatalks.club/sma-zoomcamp-2025/homework/hw01\n",
    "\n",
    "## Leaderboard\n",
    "\n",
    "Leaderboard link:\n",
    "https://courses.datatalks.club/sma-zoomcamp-2025/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10462e76-66ef-45e0-a98e-abb1ea904edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
